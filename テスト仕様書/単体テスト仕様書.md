# 単体テスト仕様書

## 1. テスト概要

### 1.1 目的
トランスクリプト議事録生成システムの各モジュール・関数の単体テストを実施し、個別機能の正常性を確認する。

### 1.2 対象システム
- **システム名**: トランスクリプト議事録生成API
- **バージョン**: 1.0.0
- **テスト対象**: 各モジュールの個別機能

## 2. テスト環境

### 2.1 テスト実行環境
- **Python**: 3.11+
- **テストフレームワーク**: pytest
- **モックライブラリ**: unittest.mock
- **カバレッジ**: pytest-cov

### 2.2 前提条件
- 開発環境が正常に構築されていること
- 必要な依存関係がインストールされていること
- テストデータが準備されていること

## 3. テスト対象モジュール

### 3.1 config.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-CONFIG-001 | 環境変数の正常読み込み | 設定値が正しく取得される |
| UT-CONFIG-002 | 必須環境変数の未設定 | ValidationErrorが発生 |
| UT-CONFIG-003 | デフォルト値の確認 | デフォルト値が正しく設定される |

### 3.2 src/modules/azure_openai_client.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-OPENAI-001 | クライアント初期化 | AzureOpenAIクライアントが正常に作成される |
| UT-OPENAI-002 | 議事録生成（正常系） | トランスクリプトから議事録が生成される |
| UT-OPENAI-003 | 議事録生成（異常系） | API呼び出し失敗時の例外処理 |
| UT-OPENAI-004 | レスポンス解析 | APIレスポンスが正しく解析される |
| UT-OPENAI-005 | リトライ機能 | 一時的な失敗時のリトライ動作 |

### 3.3 src/modules/transcript_processor.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-PROCESSOR-001 | トランスクリプト処理（正常系） | 正常にMinutesResponseが返される |
| UT-PROCESSOR-002 | 空のトランスクリプト | 適切なエラーハンドリング |
| UT-PROCESSOR-003 | 大容量トランスクリプト | メモリ効率的な処理 |
| UT-PROCESSOR-004 | 特殊文字を含むテキスト | 文字エンコーディングの正常処理 |
| UT-PROCESSOR-005 | ログ出力確認 | 適切なログが出力される |

### 3.4 src/modules/logger.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-LOGGER-001 | ログ設定初期化 | ロガーが正常に設定される |
| UT-LOGGER-002 | ログレベル設定 | 指定したレベルでログが出力される |
| UT-LOGGER-003 | ログフォーマット | 指定したフォーマットでログが出力される |
| UT-LOGGER-004 | ファイル出力 | ログファイルに正常に出力される |

### 3.5 src/schemas/transcript.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-SCHEMA-TRANS-001 | 正常なリクエスト | バリデーションが成功する |
| UT-SCHEMA-TRANS-002 | 必須フィールド未設定 | ValidationErrorが発生 |
| UT-SCHEMA-TRANS-003 | 不正な型 | 型エラーが発生 |
| UT-SCHEMA-TRANS-004 | 文字列長制限 | 制限値での動作確認 |

### 3.6 src/schemas/minutes.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-SCHEMA-MIN-001 | 正常なレスポンス | シリアライゼーションが成功する |
| UT-SCHEMA-MIN-002 | 日時フォーマット | ISO形式での日時出力 |
| UT-SCHEMA-MIN-003 | オプションフィールド | Noneの場合の動作確認 |
| UT-SCHEMA-MIN-004 | JSON出力 | 正しいJSON形式での出力 |

### 3.7 src/routers/minutes.py
| テストケース | テスト内容 | 期待結果 |
|-------------|-----------|----------|
| UT-ROUTER-001 | 議事録生成エンドポイント | 正常なレスポンスが返される |
| UT-ROUTER-002 | バリデーションエラー | 400エラーが返される |
| UT-ROUTER-003 | 内部エラー | 500エラーが返される |
| UT-ROUTER-004 | ヘルスチェック | 正常なステータスが返される |

## 4. テストデータ

### 4.1 正常系テストデータ
```json
{
  "content": "会議開始。議題1について議論します。田中さんから報告をお願いします。",
  "meeting_title": "週次定例会議",
  "participants": ["田中", "佐藤", "鈴木"]
}
```

### 4.2 異常系テストデータ
```json
{
  "content": "",
  "meeting_title": null,
  "participants": []
}
```

### 4.3 境界値テストデータ
- 最大文字数のトランスクリプト
- 最小文字数のトランスクリプト
- 特殊文字を含むテキスト

## 5. モック設定

### 5.1 Azure OpenAI API モック
```python
@pytest.fixture
def mock_openai_client():
    with patch('src.modules.azure_openai_client.AzureOpenAI') as mock:
        mock_response = Mock()
        mock_response.choices[0].message.content = "モック議事録内容"
        mock.return_value.chat.completions.create.return_value = mock_response
        yield mock
```

### 5.2 環境変数モック
```python
@pytest.fixture
def mock_settings():
    with patch('src.config.settings') as mock:
        mock.azure_openai_api_key = "test_key"
        mock.azure_openai_model = "gpt-4"
        mock.azure_openai_version = "2023-12-01-preview"
        mock.azure_openai_endpoint = "https://test.openai.azure.com/"
        yield mock
```

## 6. テスト実行手順

### 6.1 事前準備
1. テスト環境の構築
2. 依存関係のインストール
3. テストデータの準備
4. モック設定の確認

### 6.2 実行コマンド
```bash
# 全単体テスト実行
pytest tests/unit/ -v

# カバレッジ付き実行
pytest tests/unit/ --cov=src --cov-report=html

# 特定モジュールのテスト
pytest tests/unit/test_azure_openai_client.py -v
```

### 6.3 結果確認
- テスト実行結果の確認
- カバレッジレポートの確認
- 失敗テストの原因分析

## 7. 合格基準

### 7.1 テスト成功率
- **目標**: 100%のテストケースが成功
- **最低基準**: 95%以上のテストケースが成功

### 7.2 コードカバレッジ
- **目標**: 90%以上のコードカバレッジ
- **最低基準**: 80%以上のコードカバレッジ

### 7.3 パフォーマンス
- 各テストケースの実行時間が1秒以内
- 全テストの実行時間が30秒以内

## 8. 不具合管理

### 8.1 不具合分類
- **Critical**: システム停止につながる重大な不具合
- **Major**: 主要機能に影響する不具合
- **Minor**: 軽微な不具合

### 8.2 対応方針
- Critical: 即座に修正
- Major: 次回リリースまでに修正
- Minor: 計画的に修正

## 9. テスト完了条件

- 全テストケースの実行完了
- 合格基準の達成
- 不具合の修正完了
- テスト結果レポートの作成

---

**作成日**: 2025年1月24日  
**バージョン**: 1.0  
**作成者**: AI Assistant
